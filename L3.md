# Analiza Współczynnika Uwarunkowania Macierzy

W analizie numerycznej, współczynnik uwarunkowania macierzy jest istotnym wskaźnikiem, który określa wrażliwość rozwiązania systemu równań liniowych na zmiany w wartościach macierzy. Ten współczynnik jest wyrażany jako:

$$
\kappa(A) = \|A\| \cdot \|A^{-1}\|
$$

gdzie $\|A\|$ jest normą macierzy $A$, a $\|A^{-1}\|$ jest normą macierzy odwrotnej do $A$. Współczynnik uwarunkowania można interpretować jako miarę, jak duże mogą być względne błędy w rozwiązaniu w odpowiedzi na względne błędy w danych.

## Przykład 1

W poniższym skrypcie wykorzystujemy MATLAB do zbadania wpływu niewielkiej perturbacji na współczynnik uwarunkowania losowo wygenerowanej macierzy.

```matlab
% Ustawienie seed dla generatora liczb losowych dla powtarzalności wyników
rng(0);

% Tworzenie losowej macierzy kwadratowej A o rozmiarze 5x5
A = rand(5,5);

% Obliczenie współczynnika uwarunkowania macierzy A
cond_A = cond(A);

% Wyświetlenie współczynnika uwarunkowania macierzy A
fprintf('Współczynnik uwarunkowania macierzy A: %f\n', cond_A);

% Tworzenie niewielkiej perturbacji macierzy A
epsilon = 1e-5;
B = A + epsilon * rand(5,5);

% Obliczenie współczynnika uwarunkowania macierzy B
cond_B = cond(B);

% Wyświetlenie współczynnika uwarunkowania macierzy B
fprintf('Współczynnik uwarunkowania macierzy B po perturbacji: %f\n', cond_B);

% Obliczenie różnicy między współczynnikami
diff_cond = abs(cond_B - cond_A);

% Wyświetlenie różnicy między współczynnikami uwarunkowania
fprintf('Różnica w współczynniku uwarunkowania przed i po perturbacji: %f\n', diff_cond);
```


 # Porównanie Współczynnika Uwarunkowania Macierzy Dobrze i Źle Uwarunkowanej

Współczynnik uwarunkowania macierzy jest kluczowym wskaźnikiem używanym w analizie numerycznej do oceny, jak bardzo błędy w danych wejściowych mogą wpłynąć na błędy w wynikach. Macierze dobrze uwarunkowane mają niski współczynnik uwarunkowania, co oznacza, że niewielkie błędy w danych wejściowych powodują niewielkie błędy w wynikach. Macierze źle uwarunkowane mają wysoki współczynnik uwarunkowania, co może prowadzić do dużych błędów w wynikach nawet przy niewielkich błędach w danych wejściowych.

## Skrypt MATLAB

W poniższym skrypcie MATLAB, demonstrujemy różnicę między macierzą dobrze uwarunkowaną a macierzą źle uwarunkowaną. Skrypt rozwiązuje system równań liniowych dla obu macierzy, wprowadza niewielką perturbację do wektora wyników, rozwiązuje systemy równań ponownie, a następnie porównuje różnicę w rozwiązaniach.

```matlab
% Dobrze uwarunkowana macierz - macierz jednostkowa
A_well = eye(5);

% Wartość współczynnika uwarunkowania dla macierzy dobrze uwarunkowanej
cond_well = cond(A_well);

% Źle uwarunkowana macierz - macierz diagonalna z dużymi różnicami między wartościami
A_ill = diag([1e-10, 1e-5, 1, 1e5, 1e10]);

% Wartość współczynnika uwarunkowania dla macierzy źle uwarunkowanej
cond_ill = cond(A_ill);

% Tworzenie wektora wyników
b = [1; 2; 3; 4; 5];

% Rozwiązanie systemów równań
x_well = A_well\b;
x_ill = A_ill\b;

% Perturbacja wektora wyników
delta_b = 1e-5 * rand(5,1);
b_perturbed = b + delta_b;

% Rozwiązanie systemów równań z perturbowanym wektorem wyników
x_well_perturbed = A_well\b_perturbed;
x_ill_perturbed = A_ill\b_perturbed;

% Obliczenie i wyświetlenie różnicy rozwiązań
diff_well = norm(x_well - x_well_perturbed);
diff_ill = norm(x_ill - x_ill_perturbed);

```

# Właściwości Macierzy z Dobrymi i Złymi Współczynnikami Uwarunkowania

Współczynnik uwarunkowania macierzy ($\kappa(A)$) jest miarą wrażliwości funkcji numerycznej – na przykład rozwiązania systemu równań liniowych – na błędy w danych. Macierz może mieć dobry (niski) lub zły (wysoki) współczynnik uwarunkowania, co ma wpływ na stabilność obliczeń.

## Macierze z Dobrymi Współczynnikami Uwarunkowania

Macierze z dobrymi współczynnikami uwarunkowania charakteryzują się tym, że:

- Wszystkie wartości własne są duże w porównaniu do największej wartości własnej.
- Wartości własne macierzy są od siebie oddalone, co oznacza, że macierz nie jest bliska macierzy osobliwej.
- Dla macierzy symetrycznych i dodatnio określonych współczynnik uwarunkowania często jest niski.

Przykłady macierzy dobrze uwarunkowanych to:

- Macierze jednostkowe, dla których $\kappa(I) = 1$.
- Macierze, których wartości własne są wszystkie zbliżone wartościowo.

## Macierze z Złymi Współczynnikami Uwarunkowania

Macierze źle uwarunkowane są przeciwieństwem tych dobrze uwarunkowanych i charakteryzują się:

- Małymi wartościami własnymi w porównaniu do największej wartości własnej.
- Wysoką wrażliwością na perturbacje, co może prowadzić do znaczących błędów w rozwiązaniach numerycznych.
- Byciem blisko macierzy osobliwej, gdzie macierz osobliwa to taka, która nie ma macierzy odwrotnej.

Przykłady macierzy źle uwarunkowanych to:

- Macierze, które mają bardzo duże rozstępy między wartościami własnymi.
- Macierze o wysokiej różnicy między najmniejszym a największym elementem diagonalnym (w przypadku macierzy diagonalnych).

## Poprawianie Współczynnika Uwarunkowania Macierzy

Istnieje kilka technik, które mogą pomóc poprawić współczynnik uwarunkowania macierzy:

1. **Skalowanie macierzy**: Przeskalowanie macierzy może zmniejszyć różnice między jej wartościami własnymi i tym samym poprawić współczynnik uwarunkowania.

2. **Regularizacja**: Dodanie małej wartości na przekątnej macierzy (proces znany jako regularizacja Tikhonova) może pomóc uniknąć problemów z macierzami osobliwymi lub źle uwarunkowanymi.

3. **Prekondycjonowanie**: Użycie prekondycjonera do transformacji macierzy do formy o lepszych właściwościach numerycznych przed zastosowaniem metody iteracyjnej.

4. **Wybór odpowiedniej metody numerycznej**: Niektóre algorytmy są lepiej przystosowane do pracy z macierzami źle uwarunkowanymi i mogą zawierać mechanizmy kompensujące błędy numeryczne.

# Poprawianie Współczynnika Uwarunkowania Macierzy w MATLAB

W tym przykładzie zobaczymy, jak można poprawić współczynnik uwarunkowania macierzy za pomocą skalowania i regularizacji. Metoda ta jest szczególnie przydatna dla macierzy źle uwarunkowanych, które mogą prowadzić do niestabilności w obliczeniach numerycznych.

## Skalowanie

Skalowanie polega na przemnożeniu macierzy przez diagonalną macierz skalującą w celu zrównoważenia wielkości jej elementów.

```matlab
% Tworzenie źle uwarunkowanej macierzy A
A = diag([1e-10, 1e-5, 1, 1e5, 1e10]);

% Obliczanie współczynnika uwarunkowania macierzy A
cond_A = cond(A);

% Tworzenie macierzy skalującej S
S = diag(1./sqrt(diag(A)));

% Skalowanie macierzy A
A_scaled = S * A * S;

% Obliczanie współczynnika uwarunkowania skalowanej macierzy A
cond_A_scaled = cond(A_scaled);

% Wyświetlanie wyników
fprintf('Współczynnik uwarunkowania przed skalowaniem: %e\n', cond_A);
fprintf('Współczynnik uwarunkowania po skalowaniu: %e\n', cond_A_scaled);
```


### Skalowanie Macierzy

Skalowanie macierzy to proces, który zmienia zakres jej elementów w celu poprawy dokładności obliczeń, ale faktycznie nie zmienia problemu, który macierz ta reprezentuje. Skalowanie jest często stosowane w problemach optymalizacji i rozwiązywaniu systemów równań liniowych, aby zapobiec przekłamaniom numerycznym spowodowanym przez wartości o bardzo różnej wielkości. Skalowanie przeprowadza się przez przemnożenie macierzy przez macierz diagonalną z lewej (skalowanie wierszy) i prawej (skalowanie kolumn), co nie zmienia rozwiązania systemu równań liniowych.

```matlab
% Przykład skalowania
D = diag(1 ./ sqrt(diag(A))); % Macierz skalująca
A_scaled = D * A * D;         % Skalowana macierz A
```

Rozwiązanie systemu równań `Ax = b` zostanie zmienione na `DADy = Db`, gdzie `y = D^-1x`. Rozwiązanie `x` systemu oryginalnego jest więc skalowane przez `D^-1` i pozostaje tożsame z rozwiązaniem `y` systemu skalowanego.

### Regularizacja Macierzy

Regularizacja, tak jak regularizacja Tikhonova, jest techniką służącą do stabilizacji problemu źle uwarunkowanego lub osobliwego poprzez dodanie małej wartości do przekątnych elementów macierzy. Jednakże w przeciwieństwie do skalowania, regularizacja faktycznie zmienia problem, który rozwiązujemy. Dzieje się tak, ponieważ poprzez dodanie termu regularizacyjnego do macierzy `A`, otrzymujemy macierz `A + λI`, która ma inne właściwości i różni się od oryginalnej macierzy `A`.

```matlab
% Przykład regularizacji
lambda = 1e-10;               % Parametr regularizacji
A_regularized = A + lambda * eye(size(A)); % Zregularizowana macierz A
```

Regularizacja jest często używana w kontekście problemów odwrotnych i analizy danych, gdzie nieco zmieniamy problem w celu uzyskania bardziej stabilnego lub interpretowalnego rozwiązania.

Obie metody są używane w praktyce numerycznej, ale ważne jest, aby zrozumieć, jak każda z nich wpływa na problem i jakie mogą być konsekwencje tych zmian w kontekście danego zastosowania.





# Algorytmy do Znajdowania Współczynnika Uwarunkowania Macierzy

Algorytmy numeryczne stosowane do znajdowania współczynnika uwarunkowania macierzy pozwalają na ocenę stabilności problemów matematycznych i efektywność algorytmów numerycznych.

## Metody i Ich Charakterystyka

### 1. Bezpośrednie Obliczenie za pomocą Normy Macierzy

Współczynnik uwarunkowania $\kappa(A)$ macierzy $A$ można obliczyć bezpośrednio jako:

$$
\kappa(A) = \|A\| \cdot \|A^{-1}\|
$$

**Zalety:**
- Prostota i bezpośredniość.
- Dokładność dla macierzy o małych rozmiarach.

**Wady:**
- Wymaga obliczenia macierzy odwrotnej, co jest kosztowne obliczeniowo.
- Niezalecane dla macierzy źle uwarunkowanych lub dużych.

### 2. Użycie Wartości Osobliwych

Współczynnik dla normy spektralnej (normy 2) można obliczyć jako:

$$
\kappa_2(A) = \frac{\sigma_{max}}{\sigma_{min}}
$$

gdzie $\sigma_{max}$ i $\sigma_{min}$ to największa i najmniejsza wartość osobliwa macierzy $A$.

**Zalety:**
- Bardziej efektywne dla dużych macierzy.
- Unika bezpośredniego obliczenia macierzy odwrotnej.

**Wady:**
- Wymaga obliczenia rozkładu SVD, co może być kosztowne.

### 3. Metody Iteracyjne (np. Metoda Potęgowa)

Metody iteracyjne, takie jak metoda potęgowa, szukają największej wartości własnej, a jej odwrotność dla najmniejszej wartości własnej.

**Zalety:**
- Skuteczne dla dominujących wartości własnych.
- Dobre do przybliżonych obliczeń.

**Wady:**
- Może być wolne i mniej dokładne dla wartości własnych o podobnych wielkościach.

## Ogólny Schemat Algorytmu

1. Wybierz metodę w zależności od właściwości macierzy i wymagań obliczeniowych.
2. Dla metod bezpośrednich, oblicz normy macierzy i jej odwrotności.
3. Dla metod z wartościami osobliwymi, użyj rozkładu SVD do znalezienia wartości $\sigma_{max}$ i $\sigma_{min}$.
4. Dla metod iteracyjnych, zaimplementuj iterację do znalezienia dominującej wartości własnej i jej odwrotności dla najmniejszej wartości własnej.
5. Oblicz współczynnik uwarunkowania $\kappa(A)$.

## Zadanie 

Napisz algorytm w MATLAB, który wykorzystuje metodę iteracyjną do znalezienia współczynnika uwarunkowania macierzy. Użyj metody potęgowej do obliczenia największej wartości własnej i metody potęgowej dla macierzy odwrotnej, aby znaleźć najmniejszą wartość własną. Porównaj wyniki ze współczynnikiem uwarunkowania obliczonym za pomocą wbudowanej funkcji `cond`.

**Wskazówka:** Rozpocznij od losowo wygenerowanej macierzy symetrycznej dodatnio określonej, aby zapewnić rzeczywiste wartości własne.

### Przykładowy Kod Startowy

```matlab
% Wygeneruj symetryczną, dodatnio określoną macierz A
A = rand(10, 10);
A = A'*A;

% Zaimplementuj metodę potęgową dla macierzy A

% Zaimplementuj metodę potęgową dla A^-1

% Porównaj współczynnik uwarunkowania z funkcją 'cond'
```


# Wartości Własne i Wektory Własne Macierzy

Wartości własne i wektory własne macierzy są fundamentalnymi pojęciami w algebrze liniowej, które odgrywają kluczową rolę w interpretacji transformacji liniowych. Pozwalają one na zrozumienie, jak macierz transformuje przestrzeń wektorową. Wartości własne informują nas o skali transformacji wzdłuż odpowiadających im wektorów własnych, natomiast wektory własne wskazują kierunki, wzdłuż których ta transformacja jest najbardziej znacząca.

# Praktyczna Interpretacja Wartości i Wektorów Własnych Macierzy

Wartości własne i wektory własne macierzy są kluczowe w wielu praktycznych zastosowaniach, oferując intuicyjne zrozumienie wpływu transformacji liniowej na różne systemy i dane. Oto kilka przykładów, jak wartości i wektory własne są interpretowane i wykorzystywane w praktyce:

## Analiza Składowych Głównych (PCA)

W statystyce i uczeniu maszynowym, PCA wykorzystuje wartości i wektory własne do identyfikacji kierunków, wzdłuż których dane mają największą wariancję. W praktyce:
- **Wektory własne** reprezentują kierunki (składowe główne) w przestrzeni danych, które maksymalizują wariancję.
- **Wartości własne** określają, jak duża jest wariancja wzdłuż tych kierunków. Większe wartości własne wskazują na większą wariancję, co oznacza, że dany kierunek jest bardziej znaczący dla struktury danych.

## Dynamika Systemów

W inżynierii i fizyce, analiza systemów dynamicznych często opiera się na wartościach własnych macierzy systemu:
- **Wartości własne** mogą wskazywać na stabilność systemu. Na przykład, w układach liniowych, system jest stabilny, jeśli wszystkie wartości własne mają ujemne części rzeczywiste.
- **Wektory własne** wskazują kierunki, w których odpowiedzi systemu dynamicznego na perturbacje zewnętrzne są najbardziej wyraźne.

## Mechanika Kwantowa

W fizyce kwantowej, wartości i wektory własne operatorów (które są reprezentowane przez macierze) mają fundamentalne znaczenie:
- **Wartości własne** operatora reprezentują możliwe wyniki pomiarów danej wielkości fizycznej.
- **Wektory własne** odpowiadają stanom, w których pomiar tej wielkości daje określony wynik. To znaczy, że jeśli system kwantowy jest w stanie opisanym przez wektor własny, pomiar odpowiedniej wielkości zawsze zwróci wartość własną odpowiadającą temu wektorowi.

## Grafika Komputerowa i Analiza Sieci

W grafice komputerowej i analizie sieci:
- **Wartości własne** i **wektory własne** są wykorzystywane do optymalizacji algorytmów renderowania, takich jak iteracyjne metody najmniejszych kwadratów, które mogą wykorzystywać dekompozycję według wartości własnych do przyspieszenia obliczeń.
- W analizie sieci, wartości własne macierzy sąsiedztwa mogą informować o ogólnej strukturze sieci, np. o jej spójności czy możliwych klastrach.

Wartości i wektory własne dostarczają zatem nie tylko matematycznych informacji o macierzach, ale także mają bezpośredni wpływ na interpretację i zrozumienie fizycznych, statystycznych i inżynierskich systemów, oferując praktyczne narzędzia do analizy i optymalizacji w wielu dziedzinach nauki i techniki.



## Definicja

Dla danej macierzy kwadratowej $A$, wartość własna $\lambda$ i odpowiadający jej wektor własny $v$ spełniają równanie:

$$
A v = \lambda v
$$

gdzie:
- $A$ jest macierzą kwadratową,
- $v$ jest wektorem własnym macierzy $A$,
- $\lambda$ jest wartością własną odpowiadającą wektorowi własnym $v$.

## Znaczenie

Wartości własne wskazują na skalę, w jakiej odpowiadający im wektor własny jest rozciągany lub ściskany przez macierz. Wektory własne wskazują kierunki, wzdłuż których działanie macierzy może być opisane jako czyste skalowanie.

## Obliczanie w MATLAB

Do obliczenia wartości i wektorów własnych w MATLAB można użyć funkcji `eig`:

```matlab
A = [2 1; 1 2];
[V, D] = eig(A);
```

W powyższym przykładzie `D` jest macierzą diagonalną zawierającą wartości własne macierzy $A$, a kolumny `V` to odpowiadające im wektory własne.

## Zastosowanie

Wartości i wektory własne mają kluczowe znaczenie w wielu zastosowaniach, w tym w:
- Analizie PCA (Principal Component Analysis) w statystyce,
- Badaniu stabilności systemów dynamicznych,
- Rozwiązaniu układów równań różniczkowych,
- Projektowaniu algorytmów graficznych i optymalizacji.




Oczywiście, omówmy najpierw najpopularniejsze algorytmy numeryczne używane do obliczania wartości własnych, a następnie przedstawimy ogólny schemat, na podstawie którego studenci będą mogli realizować zadania.

## Algorytmy Numeryczne do Obliczania Wartości Własnych

Obliczanie wartości i wektorów własnych macierzy jest kluczowym problemem w numerycznej algebrze liniowej. Istnieje wiele metod, które można zastosować w zależności od rodzaju i rozmiaru macierzy:

### 1. Metoda Potęgowa
Metoda potęgowa jest jednym z najprostszych algorytmów iteracyjnych używanych do znalezienia dominującej wartości własnej (tej o największej wartości bezwzględnej) i odpowiadającego jej wektora własnego macierzy. Jest szczególnie efektywna, gdy różnica między największą a kolejną wartością własną jest duża.

**Schemat algorytmu:**
- Wybierz początkowy wektor $x$, który nie jest ortogonalny do dominującego wektora własnego.
- Iteracyjnie obliczaj $x = Ax$.
- Normalizuj $x$ po każdej iteracji.
- Oszacuj wartość własną jako $\lambda = x^T A x$.

### 2. Metoda QR
Metoda QR jest bardziej złożonym, ale bardzo stabilnym algorytmem służącym do obliczenia wszystkich wartości własnych macierzy. Polega na iteracyjnym przekształcaniu macierzy do formy trójkątnej, z której łatwo odczytać wartości własne.

**Schemat algorytmu:**
- Rozkład macierzy $A$ na iloczyn macierzy ortogonalnej $Q$ i górnotrójkątnej $R$.
- Formuj nową macierz $A' = RQ$.
- Powtarzaj proces do osiągnięcia zbieżności - macierz $A'$ zbiega do formy, w której na przekątnej znajdują się wartości własne.

### 3. Rozkład SVD (Singular Value Decomposition)
Chociaż SVD nie jest bezpośrednio metodą na wartości własne, można go wykorzystać do ich obliczenia, szczególnie w przypadku macierzy niekwadratowych. SVD rozkłada macierz na iloczyn trzech macierzy, gdzie jedna z nich zawiera wartości osobliwe, które dla macierzy kwadratowych są wartościami własnymi.

**Schemat algorytmu:**
- Rozłóż macierz $A$ na $U\Sigma V^T$, gdzie $\Sigma$ zawiera wartości osobliwe.
- Dla macierzy kwadratowych, wartości na przekątnej $\Sigma$ to wartości własne $A$.

## Zadanie 

Na podstawie powyższych algorytmów, zadaniem będzie napisanie funkcji w MATLAB, która obliczy wartości własne i wektory własne danej macierzy, używając wybranej metody. Należy zbadać, jak różne właściwości macierzy, takie jak jej rozmiar czy rodzaj (symetryczna, niesymetryczna), wpływają na wybór i efektywność metody.

```matlab
function [values, vectors] = eigen_properties(A)
    [vectors, values] = eig(A);
    % Wyświetl wartości i wektory własne
    disp('Wartości własne:');
    disp(diag(values));
    disp('Wektory własne:');
    disp(vectors);
end

% Przykład użycia:
A = [2 1; 1 2];
[eigenvalues, eigenvectors] = eigen_properties(A);
```






